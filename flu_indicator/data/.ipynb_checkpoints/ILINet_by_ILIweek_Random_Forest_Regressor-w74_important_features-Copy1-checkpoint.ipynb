{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final df for model building\n",
    "df1 = pd.read_csv(\"ML_model_wk40_to_20.csv\")\n",
    "df1.dropna(how='any', inplace=True)\n",
    "del df1['ILI_weeks']\n",
    "del df1['Unnamed: 0']\n",
    "#del df1['week']\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combining year and week column \n",
    "def combine_year_week(row):\n",
    "    return int(row[\"Year\"]) * 100 + int(row[\"week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"YearWeek\"] = df1.apply(combine_year_week, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to YearWeek\n",
    "df1.index = df1[\"YearWeek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df1.drop([\"Year\", \"week\", \"YearWeek\"], axis=1)\n",
    "model_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_74important_features_df = model_df[['CDC_Unweighted_ILI',\n",
    " 'type_a_influenza',\n",
    " 'influenza_type_a',\n",
    " 'Flu_Visit_Count',\n",
    " 'ILI_Visit_Count',\n",
    " 'how_to_treat_flu',\n",
    " 'flu_remedy',\n",
    " 'exposed_to_flu',\n",
    " 'get_over_the_flu',\n",
    " 'sinus',\n",
    " 'cure_the_flu',\n",
    " 'incubation_period_for_the_flu',\n",
    " 'treat_the_flu',\n",
    " 'how_to_treat_the_flu',\n",
    " 'low_body',\n",
    " 'influenza_treatment',\n",
    " 'oscillococcinum',\n",
    " 'flu_contagious_period',\n",
    " 'tussionex',\n",
    " 'flu_care',\n",
    " 'walking_pneumonia',\n",
    " 'Unspecified',\n",
    " 'sinus_infections',\n",
    " 'flu_germs',\n",
    " 'pneumonia',\n",
    " 'flu_complications',\n",
    " 'symptoms_of_pneumonia',\n",
    " 'braun_thermoscan',\n",
    " 'treat_flu',\n",
    " 'over_the_counter_flu_medicine',\n",
    " 'acute_bronchitis',\n",
    " 'robitussin',\n",
    " 'contagious_flu',\n",
    " 'thermoscan',\n",
    " 'fever_flu',\n",
    " 'expectorant',\n",
    " 'strep_throat',\n",
    " 'flu_contagious',\n",
    " 'flu_incubation',\n",
    " 'early_flu_symptoms',\n",
    " 'flu_remedies',\n",
    " 'flu_headache',\n",
    " 'chest_cold',\n",
    " 'cold_versus_flu',\n",
    " 'cold_and_flu',\n",
    " 'cure_flu',\n",
    " 'tussin',\n",
    " 'flu_medicine',\n",
    " 'remedies_for_the_flu',\n",
    " 'get_rid_of_the_flu',\n",
    " 'over_the_counter_flu',\n",
    " 'tessalon',\n",
    " 'influenza_incubation_period',\n",
    " 'ear_thermometer',\n",
    " 'flu_children',\n",
    " 'flu_and_fever',\n",
    " 'flu_treatments',\n",
    " 'break_a_fever',\n",
    " 'reduce_a_fever',\n",
    " 'flu_vs_cold',\n",
    " 'treating_the_flu',\n",
    " 'taking_temperature',\n",
    " 'flu_versus_cold',\n",
    " 'symptoms_of_the_flu',\n",
    " 'influenza_symptoms',\n",
    " 'bronchitis',\n",
    " 'remedies_for_flu',\n",
    " 'flu_cough',\n",
    " 'high_fever',\n",
    " 'cold_vs_flu',\n",
    " 'signs_of_the_flu',\n",
    " 'influenza_a_and_b',\n",
    " 'flu_length',\n",
    " 'body_temperature', \n",
    " 'ILI_lagwk1',\n",
    " 'ILI_lagwk2', \n",
    " 'ILI_lagwk3',\n",
    " 'ILI_lagwk4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_74important_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent variables\n",
    "        # 3 independent variables from athena EHR \n",
    "            # [(flu visit counts)/ (total patient visit counts) \n",
    "            # (ILI visit counts)/ (total patient visit counts)\n",
    "            # (unspecified viral or ILI visit counts)/ (total patient visit counts)]\n",
    "        # CDC historical CDC_Unweighted_ILI values: collected from 2009 to 2016 (week 40 to 20)\n",
    "        # 74 google search terms related to flu\n",
    "        \n",
    "      ======> 3 + 1 + 74\n",
    "      \n",
    "# Dependent variables \n",
    "        # 4 ILI weeks offset by 1 week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split df to train dataset, dataset before year2015 and week 40 used at training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = model_df[model_df.index < 201540]\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# defining  targets/labels to  y axis\n",
    "                y_train = ILI lag week 1\n",
    "\n",
    "                yy_train = ILI lag week 2\n",
    "\n",
    "                yyy_train = ILI lag week 3\n",
    "\n",
    "                yyyy_train = ILI lag week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"ILI_lagwk1\"]\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train = train[\"ILI_lagwk2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_train = train[\"ILI_lagwk3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyy_train =train[\"ILI_lagwk4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"ILI_lagwk1\", \"ILI_lagwk2\", \"ILI_lagwk3\", \"ILI_lagwk4\"], axis=1)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split df to train dataset,dataset after year2015 and week 40 used at training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_df[model_df.index >= 201540]\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[\"ILI_lagwk1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_test = test[\"ILI_lagwk2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_test = test[\"ILI_lagwk3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyy_test = test[\"ILI_lagwk4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"ILI_lagwk1\", \"ILI_lagwk2\", \"ILI_lagwk3\", \"ILI_lagwk4\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference https://shankarmsy.github.io/stories/gbrt-sklearn.html#\n",
    "\n",
    "##https://www.youtube.com/watch?v=IXZKgIsZRm0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a model for y_test = test[\"ILI_lagwk1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg1 = RandomForestRegressor(max_depth = 5, n_estimators = 300,  random_state = 0, min_samples_leaf = 8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rreg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared for ILI_lagwk1 Train: %.2f\" %rreg1.score(X_train, y_train)) \n",
    "print(\"R-squared for ILI_lagwk1 Test : %.2f\" %rreg1.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = rreg1.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values of y\n",
    "predictions = rreg1.predict(X_test)\n",
    "y_test_unraveled = y_test.values.ravel()\n",
    "y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store prediction and actual to df\n",
    "pred_df = pd.DataFrame({\"Prediction_ILI_lagwk1\": predictions1, \"Actual\": y_test_unraveled}).reset_index(drop=True)\n",
    "pred_df.index = y_test.index\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.to_csv(\"Prediction_ILI_lagwk1.csv\")\n",
    "# pred_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Create the GridSearchCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'learning_rate':[ 0.02, 0.01, 0.1, 0.05], \n",
    "#             'max_depth':[1, 3, 5 ,7], \n",
    "#             'min_samples_leaf':[3, 5, 7 ,9], \n",
    "# #             'max_features':[0.1,0.3,1.0],\n",
    "#             'n_estimators': [300, 500, 1000, 2000]\n",
    "#              } \n",
    "\n",
    "# est = GradientBoostingRegressor()\n",
    "# gs_cv = GridSearchCV(est, param_grid).fit(X_train, y_train)\n",
    "\n",
    "# # best hyperparameter setting\n",
    "\n",
    "# gs_cv.best_est "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting important features  [\"ILI_lagwk1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GBRF predictors variable importance\n",
    "# store most important variables under importances\n",
    "importances = rreg1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg1.feature_importances_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store most important variables/features under importances\n",
    "importances = rreg1.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = sorted(zip(importances, X_train.columns), reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # sort important varibles and sotre them under indices\n",
    "important_columns = []\n",
    "for fimportance, name in sorted(zip(importances, X_train.columns), reverse=True):\n",
    "    if fimportance > 0.001:\n",
    "        important_columns.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feature_columns = important_columns\n",
    "important_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features20_df = model_df[important_feature_columns]\n",
    "important_features20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_features74_df.to_csv(\"ML_model_wk40_to_20_with_74_important_features.csv\")\n",
    "# important_features74_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining important feature X train and X test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainim = important_features_df[important_features_df.index < 201540]\n",
    "# # trainim\n",
    "# # .head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_testim = important_features_df[important_features_df.index >= 201540]\n",
    "# # testim\n",
    "# # .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbrtim_ili_lag1 = GradientBoostingRegressor(n_estimators = 500, max_depth = 5) # number of sequential trees to be modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbrtim_ili_lag1.fit(X_trainim, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GBR with important features for ili_lag1 week 1\n",
    "# print(\"R-squared for Train gbrtim_ili_lag1: %.2f\" %gbrtim_ili_lag1.score(X_trainim, y_train)) \n",
    "# print(\"R-squared for Test gbrtim_ili_lag1: %.2f\" %gbrtim_ili_lag1.score(X_testim, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict the values of y with important feature extraction for ili week 1\n",
    "# predictions = gbrtim_ili_lag1.predict(X_testim)\n",
    "# y_test_unraveled = y_test.values.ravel()\n",
    "# y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the X_test and y_test data\n",
    "# Print at least 10 predictions vs their actual labels\n",
    "# predictions = gbrtim_ili_lag1.predict(X_testim)\n",
    "# print(f\"First 10 Predictions: {predictions[:10]}\")\n",
    "# print(f\"First 10 Actual labels: {y_test_unraveled[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print predictions vs their actual labels\n",
    "# pred_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test_unraveled}).reset_index(drop=True)\n",
    "# pred_df.index = y_test.index\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a model for y_test = test[\"ILI_lagwk2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg2 = RandomForestRegressor(max_depth = 5, n_estimators = 300,  random_state = 0, min_samples_leaf = 8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg2.fit(X_train, yy_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_pred = rreg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yy_test, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(yy_test, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared for ILI_lagwk2 Train: %.2f\" %rreg2.score(X_train, yy_train)) \n",
    "print(\"R-squared for ILI_lagwk2 Test: %.2f\" %rreg2.score(X_test, yy_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = rreg2.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values of y\n",
    "yy_test_unraveled = yy_test.values.ravel()\n",
    "yy_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store prediction and actual to df\n",
    "pred_df = pd.DataFrame({\"Prediction_ILI_lagwk2\": predictions2, \"Actual\": yy_test_unraveled}).reset_index(drop=True)\n",
    "pred_df.index = yy_test.index\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the GridSearchCV model\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {'learning_rate':[ 0.02, 0.01, 0.1, 0.05], \n",
    "#             'max_depth':[1, 3, 5 ,7], \n",
    "#             'min_samples_leaf':[3, 5, 7 ,9], \n",
    "# #             'max_features':[0.1,0.3,1.0],\n",
    "#             'n_estimators': [300, 500, 1000, 2000]\n",
    "#              } \n",
    "\n",
    "# est = GradientBoostingRegressor()\n",
    "# gs_cv = GridSearchCV(est, param_grid).fit(X_train, y_train)\n",
    "\n",
    "# # best hyperparameter setting\n",
    "\n",
    "# gs_cv.best_est "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting important features  [\"ILI_lagwk2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining important feature X train and X test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a model for y_test = test[\"ILI_lagwk3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg3 = RandomForestRegressor(max_depth = 5, n_estimators = 300,  random_state = 0, min_samples_leaf = 8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg3.fit(X_train, yyy_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy_pred = rreg3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yyy_test, yyy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(yyy_test, yyy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared for Train: %.2f\" %rreg3.score(X_train, yyy_train)) \n",
    "print(\"R-squared for Test: %.2f\" %rreg3.score(X_test, yyy_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = rreg3.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values of y\n",
    "predictions = rreg3.predict(X_test)\n",
    "yyy_test_unraveled = yyy_test.values.ravel()\n",
    "yyy_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"Prediction_ILI_lagwk3\": predictions3, \"Actual\": yyy_test_unraveled}).reset_index(drop=True)\n",
    "pred_df.index = yyy_test.index\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a model for y_test = test[\"ILI_lagwk4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg4 = RandomForestRegressor(max_depth = 5, n_estimators = 300,  random_state = 0, min_samples_leaf = 8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rreg4.fit(X_train, yyyy_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyy_pred = rreg4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yyyy_test, yyyy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(yyyy_test, yyyy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared for Train: %.2f\" %rreg4.score(X_train, yyyy_train)) \n",
    "print(\"R-squared for Test: %.2f\" %rreg4.score(X_test, yyyy_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values of y\n",
    "predictions4 = rreg4.predict(X_test)\n",
    "yyyy_test_unraveled = yyyy_test.values.ravel()\n",
    "yyyy_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store prediction and actual to df\n",
    "pred_df = pd.DataFrame({\"Prediction_ILI_lagwk1\": predictions4, \"Actual\": yyyy_test_unraveled}).reset_index(drop=True)\n",
    "pred_df.index = yyyy_test.index\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
